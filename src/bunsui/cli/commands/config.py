"""
Configuration commands for Bunsui CLI.
"""

import click
from typing import Optional, List
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich import box
from rich.prompt import Confirm
from rich.text import Text
import json
import yaml
from pathlib import Path

from ...core.config.manager import (
    ConfigManager, 
    get_config_manager, 
    get_config_info,
    find_project_root,
    find_config_files
)
from ...core.exceptions import ConfigurationError

console = Console()


@click.group()
def config():
    """è¨­å®šç®¡ç†ã‚³ãƒãƒ³ãƒ‰"""
    pass


@config.command()
@click.argument('key')
@click.argument('value')
@click.option('--scope', type=click.Choice(['local', 'project', 'global', 'auto']), 
              default='auto', help='è¨­å®šã®ã‚¹ã‚³ãƒ¼ãƒ—')
@click.pass_context
def set(ctx: click.Context, key: str, value: str, scope: str):
    """è¨­å®šå€¤ã‚’è¨­å®š"""
    try:
        config_manager = get_config_manager()
        
        # å€¤ã®å‹å¤‰æ›
        converted_value = _convert_value(value)
        
        # è¨­å®šå€¤ã‚’è¨­å®š
        config_manager.set_value(key, converted_value)
        
        # è¨­å®šã‚’ä¿å­˜
        config_manager.save_config(scope=scope)
        
        console.print(f"[green]âœ“ è¨­å®šãŒæ­£å¸¸ã«æ›´æ–°ã•ã‚Œã¾ã—ãŸ[/green]")
        console.print(f"ã‚­ãƒ¼: {key}")
        console.print(f"å€¤: {converted_value}")
        console.print(f"ã‚¹ã‚³ãƒ¼ãƒ—: {scope}")
        
        # ä¿å­˜å…ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º
        if config_manager.loaded_config_file:
            console.print(f"ä¿å­˜å…ˆ: {config_manager.loaded_config_file}")
        
    except ConfigurationError as e:
        console.print(f"[red]è¨­å®šã‚¨ãƒ©ãƒ¼: {e}[/red]")
        raise click.Abort()
    except Exception as e:
        console.print(f"[red]è¨­å®šã‚¨ãƒ©ãƒ¼: {e}[/red]")
        raise click.Abort()


@config.command()
@click.argument('key')
@click.pass_context
def get(ctx: click.Context, key: str):
    """è¨­å®šå€¤ã‚’å–å¾—"""
    try:
        config_manager = get_config_manager()
        value = config_manager.get_value(key)
        
        if value is None:
            console.print(f"[yellow]è¨­å®šã‚­ãƒ¼ '{key}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“[/yellow]")
        else:
            console.print(f"[bold cyan]{key}[/bold cyan]: {value}")
            
    except ConfigurationError as e:
        console.print(f"[red]è¨­å®šã‚¨ãƒ©ãƒ¼: {e}[/red]")
        raise click.Abort()
    except Exception as e:
        console.print(f"[red]è¨­å®šã‚¨ãƒ©ãƒ¼: {e}[/red]")
        raise click.Abort()


@config.command()
@click.argument('key')
@click.pass_context
def delete(ctx: click.Context, key: str):
    """è¨­å®šå€¤ã‚’å‰Šé™¤"""
    try:
        config_manager = get_config_manager()
        config_manager.delete_value(key)
        config_manager.save_config()
        
        console.print(f"[green]âœ“ è¨­å®šã‚­ãƒ¼ '{key}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸ[/green]")
        
    except ConfigurationError as e:
        console.print(f"[red]è¨­å®šã‚¨ãƒ©ãƒ¼: {e}[/red]")
        raise click.Abort()
    except Exception as e:
        console.print(f"[red]è¨­å®šã‚¨ãƒ©ãƒ¼: {e}[/red]")
        raise click.Abort()


@config.command()
@click.option('--scope', type=click.Choice(['all', 'local', 'project', 'global']), 
              default='all', help='è¡¨ç¤ºã™ã‚‹è¨­å®šã®ã‚¹ã‚³ãƒ¼ãƒ—')
@click.option('--format', type=click.Choice(['table', 'json', 'yaml']), 
              default='table', help='å‡ºåŠ›å½¢å¼')
@click.option('--verbose', '-v', is_flag=True, help='è©³ç´°è¡¨ç¤ºï¼ˆã™ã¹ã¦ã®è¨­å®šé …ç›®ã‚’è¡¨ç¤ºï¼‰')
@click.option('--show-defaults', is_flag=True, help='ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚‚è¡¨ç¤º')
@click.option('--check-version', is_flag=True, help='ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯')
@click.pass_context
def list(ctx: click.Context, scope: str, format: str, verbose: bool, show_defaults: bool, check_version: bool):
    """è¨­å®šã‚’è¡¨ç¤º"""
    try:
        if check_version:
            _check_config_versions()
            return
            
        if format == 'table':
            if verbose:
                _display_all_configs(format, verbose, show_defaults)
            else:
                _display_scope_config(scope, format, verbose, show_defaults)
        else:
            _display_scope_config(scope, format, verbose, show_defaults)
            
    except Exception as e:
        console.print(f"[red]è¨­å®šã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}[/red]")
        raise click.Abort()


@config.command()
@click.pass_context
def info(ctx: click.Context):
    """è¨­å®šæƒ…å ±ã‚’è¡¨ç¤º"""
    try:
        config_info = get_config_info()
        
        # ãƒ‘ãƒãƒ«ã§æƒ…å ±ã‚’è¡¨ç¤º
        info_text = []
        
        # ç¾åœ¨èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
        if config_info['loaded_config_file']:
            info_text.append(f"[green]ç¾åœ¨ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«:[/green] {config_info['loaded_config_file']}")
        else:
            info_text.append("[yellow]è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨[/yellow]")
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
        if config_info['project_root']:
            info_text.append(f"[blue]ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ:[/blue] {config_info['project_root']}")
        
        # ç’°å¢ƒå¤‰æ•°ã§ã®è¨­å®š
        if config_info['environment_config']:
            info_text.append(f"[cyan]ç’°å¢ƒå¤‰æ•°BUNSUI_CONFIG_FILE:[/cyan] {config_info['environment_config']}")
        
        console.print(Panel(
            "\n".join(info_text),
            title="ğŸ”§ Bunsui è¨­å®šæƒ…å ±",
            border_style="cyan"
        ))
        
        # æ¤œç´¢ãƒ‘ã‚¹ã‚’è¡¨ç¤º
        table = Table(title="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ãƒ‘ã‚¹ï¼ˆå„ªå…ˆé †ä½é †ï¼‰", box=box.ROUNDED)
        table.add_column("å„ªå…ˆé †ä½", style="cyan", width=8)
        table.add_column("ãƒ‘ã‚¹", style="white")
        table.add_column("å­˜åœ¨", style="bold")
        
        for i, path in enumerate(config_info['search_paths'], 1):
            exists = "âœ“" if path in config_info['existing_config_files'] else "âœ—"
            exists_style = "green" if exists == "âœ“" else "red"
            table.add_row(str(i), path, f"[{exists_style}]{exists}[/{exists_style}]")
        
        console.print(table)
        
    except Exception as e:
        console.print(f"[red]æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}[/red]")
        raise click.Abort()


@config.command()
@click.argument('file_path')
@click.option('--format', type=click.Choice(['yaml', 'json']), 
              help='ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå½¢å¼ï¼ˆè‡ªå‹•æ¤œå‡ºã•ã‚Œãªã„å ´åˆï¼‰')
@click.option('--scope', type=click.Choice(['local', 'project', 'global', 'current']), 
              default='current', help='ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹è¨­å®šã®ã‚¹ã‚³ãƒ¼ãƒ—')
@click.pass_context
def export(ctx: click.Context, file_path: str, format: Optional[str], scope: str):
    """è¨­å®šã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    try:
        config_manager = get_config_manager()
        
        output_file = Path(file_path)
        
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è‡ªå‹•æ¤œå‡º
        if not format:
            if output_file.suffix.lower() in ['.yaml', '.yml']:
                format = 'yaml'
            elif output_file.suffix.lower() == '.json':
                format = 'json'
            else:
                format = 'yaml'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        # è¨­å®šã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        config_str = config_manager.export_config(format)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        output_file.parent.mkdir(parents=True, exist_ok=True)
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(config_str)
        
        console.print(f"[green]âœ“ è¨­å®šã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ[/green]")
        console.print(f"ãƒ•ã‚¡ã‚¤ãƒ«: {output_file}")
        console.print(f"å½¢å¼: {format}")
        console.print(f"ã‚¹ã‚³ãƒ¼ãƒ—: {scope}")
        
    except ConfigurationError as e:
        console.print(f"[red]è¨­å®šã‚¨ãƒ©ãƒ¼: {e}[/red]")
        raise click.Abort()
    except Exception as e:
        console.print(f"[red]ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}[/red]")
        raise click.Abort()


@config.command()
@click.argument('archive_path')
@click.option('--include-secrets', is_flag=True, 
              help='ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å«ã‚ã‚‹ï¼ˆæ³¨æ„ï¼šæ©Ÿå¯†æƒ…å ±ãŒå«ã¾ã‚Œã¾ã™ï¼‰')
@click.option('--include-samples', is_flag=True, default=True,
              help='ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å«ã‚ã‚‹')
@click.option('--scope', type=click.Choice(['local', 'project', 'global', 'all']), 
              default='project', help='ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ã‚¹ã‚³ãƒ¼ãƒ—')
@click.pass_context
def backup(ctx: click.Context, archive_path: str, include_secrets: bool, 
           include_samples: bool, scope: str):
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®šã®å®Œå…¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ"""
    try:
        import tarfile
        import tempfile
        import shutil
        from datetime import datetime
        
        archive_file = Path(archive_path)
        if not archive_file.suffix:
            # æ‹¡å¼µå­ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ .tar.gz ã‚’è¿½åŠ 
            archive_file = archive_file.with_suffix('.tar.gz')
        
        console.print(f"[cyan]è¨­å®šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆä¸­...[/cyan]")
        console.print(f"ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: {archive_file}")
        console.print(f"ã‚¹ã‚³ãƒ¼ãƒ—: {scope}")
        console.print(f"ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆå«ã‚€: {include_secrets}")
        console.print(f"ã‚µãƒ³ãƒ—ãƒ«å«ã‚€: {include_samples}")
        
        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ
        with tempfile.TemporaryDirectory() as temp_dir:
            backup_dir = Path(temp_dir) / 'bunsui-backup'
            backup_dir.mkdir()
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            metadata = {
                'backup_created_at': datetime.utcnow().isoformat(),
                'bunsui_version': '1.0.0',  # TODO: å®Ÿéš›ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å–å¾—
                'scope': scope,
                'include_secrets': include_secrets,
                'include_samples': include_samples,
                'project_root': str(find_project_root()) if find_project_root() else None,
                'current_directory': str(Path.cwd())
            }
            
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
            collected_files = _collect_config_files(scope, include_secrets, include_samples)
            
            if not collected_files:
                console.print("[yellow]ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“[/yellow]")
                return
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼
            for source_path, relative_path in collected_files:
                dest_path = backup_dir / relative_path
                dest_path.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(source_path, dest_path)
                console.print(f"[dim]  + {relative_path}[/dim]")
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
            with open(backup_dir / 'metadata.json', 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2)
            
            # tarãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            archive_file.parent.mkdir(parents=True, exist_ok=True)
            with tarfile.open(archive_file, 'w:gz') as tar:
                tar.add(backup_dir, arcname='bunsui-backup')
        
        console.print(f"[green]âœ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒå®Œäº†ã—ã¾ã—ãŸ: {archive_file}[/green]")
        console.print(f"ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(collected_files)}")
        
        if include_secrets:
            console.print("[red]âš  æ³¨æ„: ã“ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«ã¯æ©Ÿå¯†æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™[/red]")
        
    except Exception as e:
        console.print(f"[red]ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}[/red]")
        raise click.Abort()


@config.command()
@click.argument('archive_path')
@click.option('--target-dir', help='ãƒªã‚¹ãƒˆã‚¢å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰')
@click.option('--dry-run', is_flag=True, help='å®Ÿéš›ã«ãƒªã‚¹ãƒˆã‚¢ã›ãšã«å†…å®¹ã‚’è¡¨ç¤º')
@click.option('--force', is_flag=True, help='æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¼·åˆ¶ä¸Šæ›¸ã')
@click.pass_context
def restore(ctx: click.Context, archive_path: str, target_dir: Optional[str], 
            dry_run: bool, force: bool):
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰è¨­å®šã‚’ãƒªã‚¹ãƒˆã‚¢"""
    try:
        import tarfile
        import tempfile
        
        archive_file = Path(archive_path)
        if not archive_file.exists():
            console.print(f"[red]ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {archive_file}[/red]")
            raise click.Abort()
        
        target_path = Path(target_dir) if target_dir else Path.cwd()
        
        console.print(f"[cyan]è¨­å®šã‚’ãƒªã‚¹ãƒˆã‚¢ä¸­...[/cyan]")
        console.print(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {archive_file}")
        console.print(f"ãƒªã‚¹ãƒˆã‚¢å…ˆ: {target_path}")
        console.print(f"ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³: {dry_run}")
        
        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚’å±•é–‹
        with tempfile.TemporaryDirectory() as temp_dir:
            # tarãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹
            with tarfile.open(archive_file, 'r:gz') as tar:
                tar.extractall(temp_dir)
            
            backup_dir = Path(temp_dir) / 'bunsui-backup'
            metadata_file = backup_dir / 'metadata.json'
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            if metadata_file.exists():
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                
                console.print(f"\n[bold]ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æƒ…å ±:[/bold]")
                console.print(f"ä½œæˆæ—¥æ™‚: {metadata.get('backup_created_at', 'Unknown')}")
                console.print(f"Bunsuiãƒãƒ¼ã‚¸ãƒ§ãƒ³: {metadata.get('bunsui_version', 'Unknown')}")
                console.print(f"ã‚¹ã‚³ãƒ¼ãƒ—: {metadata.get('scope', 'Unknown')}")
                console.print(f"ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆå«ã‚€: {metadata.get('include_secrets', False)}")
                console.print(f"å…ƒã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: {metadata.get('project_root', 'Unknown')}")
            
            # ãƒªã‚¹ãƒˆã‚¢ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
            restore_files = []
            for file_path in backup_dir.rglob('*'):
                if file_path.is_file() and file_path.name != 'metadata.json':
                    relative_path = file_path.relative_to(backup_dir)
                    target_file_path = target_path / relative_path
                    restore_files.append((file_path, target_file_path, relative_path))
            
            if not restore_files:
                console.print("[yellow]ãƒªã‚¹ãƒˆã‚¢ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“[/yellow]")
                return
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º
            console.print(f"\n[bold]ãƒªã‚¹ãƒˆã‚¢å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ« ({len(restore_files)}å€‹):[/bold]")
            for _, target_file_path, relative_path in restore_files:
                status = "æ–°è¦" if not target_file_path.exists() else "ä¸Šæ›¸ã"
                status_color = "green" if status == "æ–°è¦" else "yellow"
                console.print(f"[{status_color}]{status}[/{status_color}] {relative_path}")
            
            if dry_run:
                console.print("\n[cyan]ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰ã®ãŸã‚ã€å®Ÿéš›ã®ãƒªã‚¹ãƒˆã‚¢ã¯è¡Œã„ã¾ã›ã‚“[/cyan]")
                return
            
            # ç¢ºèª
            if not force:
                overwrite_files = [f for f in restore_files if f[1].exists()]
                if overwrite_files and not Confirm.ask(f"{len(overwrite_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸Šæ›¸ãã•ã‚Œã¾ã™ã€‚ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ"):
                    console.print("[yellow]ãƒªã‚¹ãƒˆã‚¢ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ[/yellow]")
                    return
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªã‚¹ãƒˆã‚¢
            import shutil
            for source_path, target_file_path, relative_path in restore_files:
                target_file_path.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(source_path, target_file_path)
                console.print(f"[green]âœ“[/green] {relative_path}")
        
        console.print(f"\n[green]âœ“ ãƒªã‚¹ãƒˆã‚¢ãŒå®Œäº†ã—ã¾ã—ãŸ[/green]")
        console.print(f"ãƒªã‚¹ãƒˆã‚¢ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(restore_files)}")
        
        if metadata.get('include_secrets'):
            console.print("[red]âš  æ³¨æ„: ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒªã‚¹ãƒˆã‚¢ã•ã‚Œã¾ã—ãŸ[/red]")
        
    except Exception as e:
        console.print(f"[red]ãƒªã‚¹ãƒˆã‚¢ã‚¨ãƒ©ãƒ¼: {e}[/red]")
        raise click.Abort()


def _repair_config_file(config_file: Path):
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿®å¾©"""
    import re
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    with open(config_file, 'r') as f:
        content = f.read()
    
    # Pythonã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚°ã‚’å‰Šé™¤
    # !!python/object/apply:bunsui.aws.dynamodb.schemas.TableName ã‚’å‰Šé™¤
    content = re.sub(r'\? !!python/object/apply:bunsui\.aws\.dynamodb\.schemas\.TableName\s*\n\s*-\s*([^\n]+)\s*\n\s*:\s*([^\n]+)', r'\1: \2', content)
    
    # è¤‡æ•°è¡Œã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å˜ç´”ãªã‚­ãƒ¼: å€¤ã®å½¢å¼ã«å¤‰æ›
    content = re.sub(r'\? !!python/object/apply:[^\n]*\s*\n\s*-\s*([^\n]+)\s*\n\s*:\s*([^\n]+)', r'\1: \2', content)
    
    # ä¿®å¾©ã•ã‚ŒãŸå†…å®¹ã‚’ä¿å­˜
    with open(config_file, 'w') as f:
        f.write(content)


def _convert_value(value: str):
    """æ–‡å­—åˆ—å€¤ã‚’é©åˆ‡ãªå‹ã«å¤‰æ›"""
    # ãƒ–ãƒ¼ãƒ«å€¤
    if value.lower() in ['true', 'false']:
        return value.lower() == 'true'
    
    # æ•´æ•°
    try:
        return int(value)
    except ValueError:
        pass
    
    # æµ®å‹•å°æ•°ç‚¹æ•°
    try:
        return float(value)
    except ValueError:
        pass
    
    # JSONæ–‡å­—åˆ—
    try:
        return json.loads(value)
    except (json.JSONDecodeError, ValueError):
        pass
    
    # æ–‡å­—åˆ—ã¨ã—ã¦è¿”ã™
    return value


def _display_all_configs(format: str, verbose: bool = False, show_defaults: bool = False):
    """ã™ã¹ã¦ã®è¨­å®šã‚’è¡¨ç¤º"""
    from pathlib import Path
    import yaml
    import json
    
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢ãƒ‘ã‚¹
    config_paths = [
        Path.cwd() / '.bunsui' / 'config.yaml',
        Path.home() / '.bunsui' / 'config' / 'config.yaml',
        Path('/etc/bunsui/config.yaml')
    ]
    
    # æœ€åˆã«è¦‹ã¤ã‹ã£ãŸè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
    config_file = None
    for path in config_paths:
        if path.exists():
            config_file = path
            break
    
    if config_file:
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç›´æ¥èª­ã¿è¾¼ã¿
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                if config_file.suffix in ['.yaml', '.yml']:
                    config_data = yaml.safe_load(f) or {}
                else:
                    config_data = json.load(f)
            
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¡¨ç¤º
            console.print(f"[dim]ğŸ“ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {config_file}[/dim]")
        except Exception as e:
            console.print(f"[red]è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}[/red]")
            return
    else:
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨
        config_data = _get_default_config_dict()
        console.print("[dim]ğŸ“ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨[/dim]")
    
    if format == 'table':
        _display_config_table(config_data, verbose=verbose, show_defaults=show_defaults)
    elif format == 'json':
        console.print(json.dumps(config_data, indent=2, default=str))
    else:  # yaml
        console.print(yaml.dump(config_data, default_flow_style=False))


def _check_config_versions():
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
    from pathlib import Path
    from rich.table import Table
    from rich.console import Console
    
    console = Console()
    
    # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³
    SUPPORTED_VERSIONS = ["1.0.0"]
    RECOMMENDED_VERSION = "1.0.0"
    
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢ãƒ‘ã‚¹
    config_paths = [
        Path.cwd() / '.bunsui' / 'config.yaml',
        Path.home() / '.bunsui' / 'config' / 'config.yaml',
        Path('/etc/bunsui/config.yaml')
    ]
    
    table = Table(title="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯", box=box.ROUNDED)
    table.add_column("ãƒ•ã‚¡ã‚¤ãƒ«", style="white", min_width=30)
    table.add_column("ãƒãƒ¼ã‚¸ãƒ§ãƒ³", style="white", min_width=10)
    table.add_column("çŠ¶æ…‹", style="white", min_width=15)
    table.add_column("æ¨å¥¨", style="white", min_width=10)
    
    found_files = []
    
    for config_path in config_paths:
        if config_path.exists():
            try:
                import yaml
                with open(config_path, 'r', encoding='utf-8') as f:
                    config_data = yaml.safe_load(f)
                
                version = config_data.get('version', 'æœªè¨­å®š')
                found_files.append((config_path, version))
                
                # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®çŠ¶æ…‹ã‚’åˆ¤å®š
                if version == 'æœªè¨­å®š':
                    status = "[red]ãƒãƒ¼ã‚¸ãƒ§ãƒ³æœªè¨­å®š[/red]"
                    recommended = RECOMMENDED_VERSION
                elif version in SUPPORTED_VERSIONS:
                    if version == RECOMMENDED_VERSION:
                        status = "[green]âœ“ æ¨å¥¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³[/green]"
                    else:
                        status = "[yellow]âš  ã‚µãƒãƒ¼ãƒˆæ¸ˆã¿[/yellow]"
                    recommended = RECOMMENDED_VERSION
                else:
                    status = "[red]âœ— éã‚µãƒãƒ¼ãƒˆ[/red]"
                    recommended = RECOMMENDED_VERSION
                
                table.add_row(
                    str(config_path),
                    version,
                    status,
                    recommended
                )
                
            except Exception as e:
                table.add_row(
                    str(config_path),
                    "ã‚¨ãƒ©ãƒ¼",
                    f"[red]èª­ã¿è¾¼ã¿å¤±æ•—: {e}[/red]",
                    RECOMMENDED_VERSION
                )
    
    if not found_files:
        console.print("[yellow]è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“[/yellow]")
        console.print(f"[dim]æ¨å¥¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {RECOMMENDED_VERSION}[/dim]")
        return
    
    console.print(table)
    
    # ã‚µãƒãƒªãƒ¼æƒ…å ±
    console.print(f"\n[bold]ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³:[/bold] {', '.join(SUPPORTED_VERSIONS)}")
    console.print(f"[bold]æ¨å¥¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³:[/bold] {RECOMMENDED_VERSION}")
    
    # æ¨å¥¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã®è­¦å‘Š
    outdated_files = [f for f, v in found_files if v != RECOMMENDED_VERSION and v != 'æœªè¨­å®š']
    if outdated_files:
        console.print(f"\n[yellow]âš  {len(outdated_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ¨å¥¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨ç•°ãªã‚Šã¾ã™[/yellow]")
        console.print("[dim]ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æ›´æ–°ã™ã‚‹ã«ã¯ 'bunsui config migrate' ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„[/dim]")


def find_project_root(start_path: Optional[Path] = None) -> Optional[Path]:
    """
    ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¦‹ã¤ã‘ã‚‹
    
    Args:
        start_path: æ¤œç´¢é–‹å§‹ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰
        
    Returns:
        ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯Noneï¼‰
    """
    current = start_path or Path.cwd()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ«ãƒ¼ãƒˆã¾ã§é¡ã‚‹
    for parent in [current] + list(current.parents):
        # Git ãƒªãƒã‚¸ãƒˆãƒªã®å ´åˆ
        if (parent / '.git').exists():
            return parent
        # pyproject.toml ãŒã‚ã‚‹å ´åˆ
        if (parent / 'pyproject.toml').exists():
            return parent
        # setup.py ãŒã‚ã‚‹å ´åˆ
        if (parent / 'setup.py').exists():
            return parent
        # package.json ãŒã‚ã‚‹å ´åˆï¼ˆNode.js ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼‰
        if (parent / 'package.json').exists():
            return parent
        # Bunsui è¨­å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒã‚ã‚‹å ´åˆ
        if (parent / '.bunsui').exists():
            return parent
    
    return None


def _display_scope_config(scope: str, format: str, verbose: bool = False, show_defaults: bool = False):
    """ç‰¹å®šã®ã‚¹ã‚³ãƒ¼ãƒ—ã®è¨­å®šã‚’è¡¨ç¤º"""
    if scope == 'all':
        # ã™ã¹ã¦ã®ã‚¹ã‚³ãƒ¼ãƒ—ã®è¨­å®šã‚’è¡¨ç¤º
        _display_all_configs(format, verbose, show_defaults)
        return
    
    project_root = find_project_root()
    scope_files = {
        'local': Path.cwd() / '.bunsui' / 'config.yaml',
        'project': project_root / '.bunsui' / 'config.yaml' if project_root else None,
        'global': Path.home() / '.bunsui' / 'config' / 'config.yaml'
    }
    
    config_file = scope_files.get(scope)
    if not config_file or not config_file.exists():
        console.print(f"[yellow]{scope} ã‚¹ã‚³ãƒ¼ãƒ—ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“[/yellow]")
        return
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            if config_file.suffix in ['.yaml', '.yml']:
                config_data = yaml.safe_load(f)
            else:
                config_data = json.load(f)
        
        if format == 'table':
            _display_config_table(config_data, verbose=verbose, show_defaults=show_defaults)
        elif format == 'json':
            console.print(json.dumps(config_data, indent=2, default=str))
        else:  # yaml
            console.print(yaml.dump(config_data, default_flow_style=False))
            
    except Exception as e:
        console.print(f"[red]è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}[/red]")


def _display_config_table(config_data: dict, verbose: bool = False, show_defaults: bool = False):
    """è¨­å®šã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º"""
    
    if verbose:
        # è©³ç´°è¡¨ç¤º: ã™ã¹ã¦ã®è¨­å®šã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–ã—ã¦è¡¨ç¤º
        _display_detailed_config_table(config_data, show_defaults)
    else:
        # ç°¡æ½”è¡¨ç¤º: ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«é‡è¦ãªè¨­å®šã®ã¿è¡¨ç¤º
        _display_summary_config_table(config_data, show_defaults)


def _display_summary_config_table(config_data: dict, show_defaults: bool = False):
    """é‡è¦ãªè¨­å®šã®ã¿ã‚’è¡¨ç¤ºã™ã‚‹ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«"""
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’å–å¾—
    default_config_data = _get_default_config_dict()
    
    # é‡è¦ãªè¨­å®šé …ç›®ã®å®šç¾©
    important_keys = {
        'åŸºæœ¬è¨­å®š': ['mode', 'version', 'created_at'],
        'AWS': ['aws.region', 'aws.profile'],
        'ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³': ['defaults.timeout_seconds', 'defaults.max_concurrent_jobs', 'defaults.output_format'],
        'ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª': ['directories.data', 'directories.cache', 'directories.logs']
    }
    
    def get_nested_value(data: dict, key_path: str):
        """ãƒã‚¹ãƒˆã—ãŸè¾æ›¸ã‹ã‚‰å€¤ã‚’å–å¾—"""
        keys = key_path.split('.')
        current = data
        for key in keys:
            if isinstance(current, dict) and key in current:
                current = current[key]
            else:
                return None
        return current
    
    def _get_version_status(version: str) -> str:
        """ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®çŠ¶æ…‹ã‚’å–å¾—"""
        SUPPORTED_VERSIONS = ["1.0.0"]
        RECOMMENDED_VERSION = "1.0.0"
        
        if version == RECOMMENDED_VERSION:
            return "[green]âœ“ æ¨å¥¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³[/green]"
        elif version in SUPPORTED_VERSIONS:
            return "[yellow]âš  ã‚µãƒãƒ¼ãƒˆæ¸ˆã¿[/yellow]"
        else:
            return "[red]âœ— éã‚µãƒãƒ¼ãƒˆ[/red]"
    
    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã‚’ç‰¹åˆ¥ã«è¡¨ç¤º
    version = get_nested_value(config_data, 'version')
    if version and isinstance(version, str):
        version_status = _get_version_status(version)
        console.print(f"\n[bold cyan]ğŸ“‹ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³:[/bold cyan] {version} {version_status}")
    
    def get_default_value_for_key(key_path: str, default_config_data: dict):
        """è¨­å®šé …ç›®ã®åå‰ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’å–å¾—"""
        # è¨­å®šé …ç›®åã®ãƒãƒƒãƒ”ãƒ³ã‚°
        key_mapping = {
            'defaults.timeout_seconds': 'pipeline.default_timeout',
            'defaults.max_concurrent_jobs': 'pipeline.max_concurrent_jobs',
            'defaults.output_format': 'logging.level',  # é©åˆ‡ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãŒãªã„å ´åˆ
            'directories.data': 'data_dir',
            'directories.cache': 'cache_dir',
            'directories.logs': 'cache_dir',  # logs_dirãŒãªã„å ´åˆã¯cache_dirã‚’ä½¿ç”¨
        }
        
        # ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚ŒãŸã‚­ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’å–å¾—
        mapped_key = key_mapping.get(key_path, key_path)
        return get_nested_value(default_config_data, mapped_key)
    
    def is_value_modified(key_path: str, current_value, default_value) -> bool:
        """å€¤ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‹ã‚‰å¤‰æ›´ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        # ãƒ‘ã‚¹ç³»ã®è¨­å®šã¯ç‰¹åˆ¥æ‰±ã„ï¼ˆçµ¶å¯¾ãƒ‘ã‚¹å±•é–‹ã•ã‚Œã‚‹ãŸã‚ï¼‰
        if any(path_key in key_path for path_key in ['data_dir', 'config_dir', 'cache_dir']):
            # ãƒ‘ã‚¹ç³»ã¯åå‰ã§åˆ¤å®š
            if hasattr(current_value, 'name'):
                current_name = current_value.name
            else:
                current_name = str(current_value).split('/')[-1] if current_value else ''
                
            if hasattr(default_value, 'name'):
                default_name = default_value.name
            else:
                default_name = str(default_value).split('/')[-1] if default_value else ''
                
            return current_name != default_name
        
        # ãã®ä»–ã¯å€¤ã§ç›´æ¥æ¯”è¼ƒ
        return current_value != default_value
    
    def get_aws_resource_names(config_data: dict) -> dict:
        """AWSãƒªã‚½ãƒ¼ã‚¹ã®å®Ÿéš›ã®åå‰ã‚’å–å¾—"""
        aws_config = config_data.get('aws', {})
        created_resources = aws_config.get('created_resources', {})
        
        resource_names = {}
        
        # DynamoDBãƒ†ãƒ¼ãƒ–ãƒ«å
        tables = created_resources.get('tables', {})
        if tables:
            table_list = []
            for table_key, table_name in tables.items():
                # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚­ãƒ¼ã‹ã‚‰çŸ­ç¸®åã‚’å–å¾—
                short_name = table_key.split('-')[-1] if '-' in table_key else table_key
                table_list.append((short_name, table_name))
            resource_names['dynamodb_tables'] = table_list
        else:
            # ä½œæˆã•ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ãŒãªã„å ´åˆã¯prefixã‚’è¡¨ç¤º
            prefix = aws_config.get('dynamodb_table_prefix', 'bunsui')
            resource_names['dynamodb_tables'] = [("prefix", f"{prefix}-*")]
        
        # S3ãƒã‚±ãƒƒãƒˆå
        buckets = created_resources.get('buckets', {})
        if buckets:
            bucket_list = []
            for bucket_type, bucket_name in buckets.items():
                bucket_list.append((bucket_type, bucket_name))
            resource_names['s3_buckets'] = bucket_list
        else:
            # ä½œæˆã•ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ãŒãªã„å ´åˆã¯prefixã‚’è¡¨ç¤º
            prefix = aws_config.get('s3_bucket_prefix', 'bunsui')
            resource_names['s3_buckets'] = [("prefix", f"{prefix}-*")]
        
        return resource_names
    
    table = Table(title="Bunsui è¨­å®šã‚µãƒãƒªãƒ¼", box=box.ROUNDED)
    table.add_column("ã‚«ãƒ†ã‚´ãƒª", style="white", min_width=12)
    table.add_column("è¨­å®šé …ç›®", style="white", min_width=25)
    table.add_column("å€¤", min_width=30)
    
    modified_count = 0
    total_count = 0
    
    for category, keys in important_keys.items():
        first_in_category = True
        for key_path in keys:
            current_value = get_nested_value(config_data, key_path)
            default_value = get_default_value_for_key(key_path, default_config_data)
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¡¨ç¤ºã—ãªã„å ´åˆã€Noneã‚„ç©ºæ–‡å­—åˆ—ã¯ã‚¹ã‚­ãƒƒãƒ—
            if not show_defaults and (current_value is None or current_value == ""):
                continue
            
            total_count += 1
            
            # æ©Ÿå¯†æƒ…å ±ã‚’ãƒã‚¹ã‚¯
            if any(secret in key_path.lower() for secret in ['password', 'secret', 'key', 'token']):
                display_value = "****"
                value_style = "red"
            else:
                display_value = str(current_value) if current_value is not None else "æœªè¨­å®š"
                if len(display_value) > 50:
                    display_value = display_value[:47] + "..."
                
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨æ¯”è¼ƒã—ã¦è‰²ã‚’æ±ºå®š
                is_modified = is_value_modified(key_path, current_value, default_value)
                
                # è‰²ã®æ±ºå®šãƒ­ã‚¸ãƒƒã‚¯ã‚’æ”¹å–„
                if key_path == 'aws.region' and current_value == 'us-east-1':
                    # AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å ´åˆã¯ç·‘è‰²
                    value_style = "green"
                elif key_path == 'defaults.timeout_seconds' and current_value == '3600':
                    # timeout_secondsãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å ´åˆã¯ç·‘è‰²
                    value_style = "green"
                elif key_path == 'defaults.max_concurrent_jobs' and current_value == '10':
                    # max_concurrent_jobsãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å ´åˆã¯ç·‘è‰²
                    value_style = "green"
                elif key_path == 'defaults.output_format' and current_value == 'INFO':
                    # output_formatãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å ´åˆã¯ç·‘è‰²
                    value_style = "green"
                elif is_modified:
                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨ç•°ãªã‚‹å ´åˆã¯é»„è‰²
                    value_style = "yellow"
                    modified_count += 1
                else:
                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨åŒã˜å ´åˆã¯ç·‘è‰²
                    value_style = "green"
            
            # è¨­å®šé …ç›®åã‚’çŸ­ç¸®
            short_key = key_path.split('.')[-1]
            
            category_display = category if first_in_category else ""
            table.add_row(
                category_display, 
                short_key, 
                Text(display_value, style=value_style)
            )
            first_in_category = False
    
    # AWSãƒªã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’è¿½åŠ 
    aws_resources = get_aws_resource_names(config_data)
    
    # DynamoDBãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±
    if 'dynamodb_tables' in aws_resources:
        first_dynamodb = True
        for table_info in aws_resources['dynamodb_tables']:
            category_display = "DynamoDB" if first_dynamodb else ""
            table.add_row(
                category_display,
                table_info[0],
                Text(table_info[1], style="cyan")
            )
            first_dynamodb = False
            total_count += 1
            modified_count += 1  # AWSãƒªã‚½ãƒ¼ã‚¹ã¯ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ¸ˆã¿ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆ
    
    # S3ãƒã‚±ãƒƒãƒˆæƒ…å ±
    if 's3_buckets' in aws_resources:
        first_s3 = True
        for bucket_info in aws_resources['s3_buckets']:
            category_display = "S3" if first_s3 else ""
            table.add_row(
                category_display,
                bucket_info[0],
                Text(bucket_info[1], style="cyan")
            )
            first_s3 = False
            total_count += 1
            modified_count += 1  # AWSãƒªã‚½ãƒ¼ã‚¹ã¯ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ¸ˆã¿ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆ
    
    console.print(table)
    
    # å¤‰æ›´çµ±è¨ˆã‚’è¡¨ç¤º
    if total_count > 0:
        percentage = (modified_count / total_count) * 100
        console.print(f"\n[dim]ğŸ“Š è¨­å®šçµ±è¨ˆ: {modified_count}/{total_count} é …ç›®ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‹ã‚‰å¤‰æ›´ã•ã‚Œã¦ã„ã¾ã™ ({percentage:.1f}%)[/dim]")
    
    # å‡¡ä¾‹ã‚’è¡¨ç¤º
    console.print("\n[dim]ğŸ¨ å‡¡ä¾‹:[/dim]")
    console.print("  [green]â– [/green] æ¨™æº–å€¤  [yellow]â– [/yellow] ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ¸ˆã¿  [red]â– [/red] æ©Ÿå¯†æƒ…å ±  [cyan]â– [/cyan] AWSãƒªã‚½ãƒ¼ã‚¹")
    
    # è©³ç´°è¡¨ç¤ºã®æ¡ˆå†…
    console.print("\n[dim]ğŸ’¡ ã™ã¹ã¦ã®è¨­å®šã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ --verbose ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„[/dim]")
    console.print("[dim]   ä¾‹: bunsui config list --verbose[/dim]")


def _flatten_dict(d, parent_key='', sep='.'):
    """ãƒã‚¹ãƒˆã—ãŸè¾æ›¸ã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–"""
    items = []
    for k, v in d.items():
        # å†…éƒ¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’é™¤å¤–
        if k.startswith('_'):
            continue
            
        new_key = f"{parent_key}{sep}{k}" if parent_key else k
        if isinstance(v, dict):
            items.extend(_flatten_dict(v, new_key, sep=sep).items())
        else:
            items.append((new_key, v))
    return dict(items)


def _display_detailed_config_table(config_data: dict, show_defaults: bool = False):
    """è©³ç´°ãªè¨­å®šã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–ã—ã¦è¡¨ç¤º"""
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’å–å¾—
    default_config_data = _get_default_config_dict()
    default_flat = _flatten_dict(default_config_data)
    
    flat_config = _flatten_dict(config_data)
    
    def get_nested_value(data: dict, key_path: str):
        """ãƒã‚¹ãƒˆã—ãŸè¾æ›¸ã‹ã‚‰å€¤ã‚’å–å¾—"""
        keys = key_path.split('.')
        current = data
        for key in keys:
            if isinstance(current, dict) and key in current:
                current = current[key]
            else:
                return None
        return current
    
    def get_default_value_for_key(key_path: str, default_config_data: dict):
        """è¨­å®šé …ç›®ã®åå‰ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’å–å¾—"""
        # è¨­å®šé …ç›®åã®ãƒãƒƒãƒ”ãƒ³ã‚°
        key_mapping = {
            'defaults.timeout_seconds': 'pipeline.default_timeout',
            'defaults.max_concurrent_jobs': 'pipeline.max_concurrent_jobs',
            'defaults.output_format': 'logging.level',  # é©åˆ‡ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãŒãªã„å ´åˆ
            'directories.data': 'data_dir',
            'directories.cache': 'cache_dir',
            'directories.logs': 'cache_dir',  # logs_dirãŒãªã„å ´åˆã¯cache_dirã‚’ä½¿ç”¨
        }
        
        # ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚ŒãŸã‚­ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’å–å¾—
        mapped_key = key_mapping.get(key_path, key_path)
        return get_nested_value(default_config_data, mapped_key)
    
    def is_value_modified(key_path: str, current_value, default_value) -> bool:
        """å€¤ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‹ã‚‰å¤‰æ›´ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        # ãƒ‘ã‚¹ç³»ã®è¨­å®šã¯ç‰¹åˆ¥æ‰±ã„ï¼ˆçµ¶å¯¾ãƒ‘ã‚¹å±•é–‹ã•ã‚Œã‚‹ãŸã‚ï¼‰
        if any(path_key in key_path for path_key in ['data_dir', 'config_dir', 'cache_dir']):
            # ãƒ‘ã‚¹ç³»ã¯åå‰ã§åˆ¤å®š
            if hasattr(current_value, 'name'):
                current_name = current_value.name
            else:
                current_name = str(current_value).split('/')[-1] if current_value else ''
                
            if hasattr(default_value, 'name'):
                default_name = default_value.name
            else:
                default_name = str(default_value).split('/')[-1] if default_value else ''
                
            return current_name != default_name
        
        # ãã®ä»–ã¯å€¤ã§ç›´æ¥æ¯”è¼ƒ
        return current_value != default_value
    
    def get_aws_resource_names(config_data: dict) -> dict:
        """AWSãƒªã‚½ãƒ¼ã‚¹ã®å®Ÿéš›ã®åå‰ã‚’å–å¾—"""
        aws_config = config_data.get('aws', {})
        created_resources = aws_config.get('created_resources', {})
        
        resource_names = {}
        
        # DynamoDBãƒ†ãƒ¼ãƒ–ãƒ«å
        tables = created_resources.get('tables', {})
        if tables:
            table_list = []
            for table_key, table_name in tables.items():
                # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚­ãƒ¼ã‹ã‚‰çŸ­ç¸®åã‚’å–å¾—
                short_name = table_key.split('-')[-1] if '-' in table_key else table_key
                table_list.append((short_name, table_name))
            resource_names['dynamodb_tables'] = table_list
        else:
            # ä½œæˆã•ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ãŒãªã„å ´åˆã¯prefixã‚’è¡¨ç¤º
            prefix = aws_config.get('dynamodb_table_prefix', 'bunsui')
            resource_names['dynamodb_tables'] = [("prefix", f"{prefix}-*")]
        
        # S3ãƒã‚±ãƒƒãƒˆå
        buckets = created_resources.get('buckets', {})
        if buckets:
            bucket_list = []
            for bucket_type, bucket_name in buckets.items():
                bucket_list.append((bucket_type, bucket_name))
            resource_names['s3_buckets'] = bucket_list
        else:
            # ä½œæˆã•ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ãŒãªã„å ´åˆã¯prefixã‚’è¡¨ç¤º
            prefix = aws_config.get('s3_bucket_prefix', 'bunsui')
            resource_names['s3_buckets'] = [("prefix", f"{prefix}-*")]
        
        return resource_names
    
    table = Table(title="Bunsui è¨­å®šï¼ˆè©³ç´°ï¼‰", box=box.ROUNDED)
    table.add_column("ã‚«ãƒ†ã‚´ãƒª", style="white", min_width=12)
    table.add_column("è¨­å®šé …ç›®", style="white", min_width=35)
    table.add_column("å€¤", min_width=30)
    
    modified_count = 0
    total_count = 0
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«è¨­å®šã‚’æ•´ç†
    categorized_config = {}
    for key, value in sorted(flat_config.items()):
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¡¨ç¤ºã—ãªã„å ´åˆã€ç©ºã®å€¤ã‚’ã‚¹ã‚­ãƒƒãƒ—
        if not show_defaults and (value is None or value == "" or 
                                 (hasattr(value, '__len__') and len(value) == 0)):
            continue
        
        # ã‚«ãƒ†ã‚´ãƒªã‚’æ±ºå®š
        if key.startswith('aws.'):
            category = 'AWS'
        elif key.startswith('pipeline.'):
            category = 'ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³'
        elif key.startswith('logging.'):
            category = 'ãƒ­ã‚°'
        elif key.startswith('security.'):
            category = 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£'
        elif key.startswith('directories.'):
            category = 'ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª'
        elif key in ['mode', 'version', 'created_at', 'environment', 'debug']:
            category = 'åŸºæœ¬è¨­å®š'
        else:
            category = 'ãã®ä»–'
        
        if category not in categorized_config:
            categorized_config[category] = []
        categorized_config[category].append((key, value))
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«è¡¨ç¤º
    for category, items in categorized_config.items():
        first_in_category = True
        for key, value in items:
            total_count += 1
            default_value = get_default_value_for_key(key, default_config_data)
            
            # æ©Ÿå¯†æƒ…å ±ã‚’éš ã™
            if any(secret in key.lower() for secret in ['password', 'secret', 'key', 'token']):
                display_value = "****"
                value_style = "red"
            else:
                display_value = str(value)
                if len(display_value) > 50:
                    display_value = display_value[:47] + "..."
                
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨æ¯”è¼ƒ
                # è‰²ã®æ±ºå®šãƒ­ã‚¸ãƒƒã‚¯ã‚’æ”¹å–„
                if key == 'aws.region' and value == 'us-east-1':
                    # AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å ´åˆã¯ç·‘è‰²
                    value_style = "green"
                elif key == 'defaults.timeout_seconds' and value == 3600:
                    # timeout_secondsãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å ´åˆã¯ç·‘è‰²
                    value_style = "green"
                elif key == 'defaults.max_concurrent_jobs' and value == 10:
                    # max_concurrent_jobsãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å ´åˆã¯ç·‘è‰²
                    value_style = "green"
                elif key == 'defaults.output_format' and value == 'INFO':
                    # output_formatãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å ´åˆã¯ç·‘è‰²
                    value_style = "green"
                elif value != default_value:
                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨ç•°ãªã‚‹å ´åˆã¯é»„è‰²
                    value_style = "yellow"
                    modified_count += 1
                else:
                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨åŒã˜å ´åˆã¯ç·‘è‰²
                    value_style = "green"
            
            # è¨­å®šé …ç›®åã‚’çŸ­ç¸®
            short_key = key.split('.')[-1] if '.' in key else key
            
            category_display = category if first_in_category else ""
            table.add_row(
                category_display,
                short_key,
                Text(display_value, style=value_style)
            )
            first_in_category = False
    
    # AWSãƒªã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’è¿½åŠ 
    aws_resources = get_aws_resource_names(config_data)
    
    # DynamoDBãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±
    if 'dynamodb_tables' in aws_resources:
        first_dynamodb = True
        for table_info in aws_resources['dynamodb_tables']:
            category_display = "DynamoDB" if first_dynamodb else ""
            table.add_row(
                category_display,
                table_info[0],
                Text(table_info[1], style="cyan")
            )
            first_dynamodb = False
            total_count += 1
            modified_count += 1  # AWSãƒªã‚½ãƒ¼ã‚¹ã¯ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ¸ˆã¿ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆ
    
    # S3ãƒã‚±ãƒƒãƒˆæƒ…å ±
    if 's3_buckets' in aws_resources:
        first_s3 = True
        for bucket_info in aws_resources['s3_buckets']:
            category_display = "S3" if first_s3 else ""
            table.add_row(
                category_display,
                bucket_info[0],
                Text(bucket_info[1], style="cyan")
            )
            first_s3 = False
            total_count += 1
            modified_count += 1  # AWSãƒªã‚½ãƒ¼ã‚¹ã¯ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ¸ˆã¿ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆ
    
    console.print(table)
    
    # å¤‰æ›´çµ±è¨ˆã‚’è¡¨ç¤º
    if total_count > 0:
        percentage = (modified_count / total_count) * 100
        console.print(f"\n[dim]ğŸ“Š è¨­å®šçµ±è¨ˆ: {modified_count}/{total_count} é …ç›®ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‹ã‚‰å¤‰æ›´ã•ã‚Œã¦ã„ã¾ã™ ({percentage:.1f}%)[/dim]")
    
    # å‡¡ä¾‹ã‚’è¡¨ç¤º
    console.print("\n[dim]ğŸ¨ å‡¡ä¾‹:[/dim]")
    console.print("  [green]â– [/green] æ¨™æº–å€¤  [yellow]â– [/yellow] ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ¸ˆã¿  [red]â– [/red] æ©Ÿå¯†æƒ…å ±  [cyan]â– [/cyan] AWSãƒªã‚½ãƒ¼ã‚¹")


def _get_default_config_dict() -> dict:
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®è¾æ›¸ã‚’å–å¾—"""
    try:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®BunsuiConfigã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        from ...core.config.models import BunsuiConfig
        default_config = BunsuiConfig()
        config_dict = default_config.model_dump(exclude={'config_file_path'})
        
        # ãƒ‡ãƒãƒƒã‚°ç”¨: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®å†…å®¹ã‚’ç¢ºèª
        # console.print(f"[dim]DEBUG: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š = {config_dict}[/dim]")
        
        return config_dict
    except Exception as e:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
        # console.print(f"[dim]DEBUG: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šå–å¾—ã‚¨ãƒ©ãƒ¼: {e}[/dim]")
        return {
            'mode': 'development',
            'version': None,
            'created_at': None,
            'aws': {
                'region': 'us-east-1',
                'profile': None,
                'dynamodb_table_prefix': 'bunsui',
                's3_bucket_prefix': 'bunsui'
            },
            'defaults': {
                'timeout_seconds': 3600,
                'max_concurrent_jobs': 5,
                'output_format': 'table'
            },
            'directories': {
                'data': str(Path.home() / '.bunsui' / 'data'),
                'cache': str(Path.home() / '.bunsui' / 'cache'),
                'logs': str(Path.home() / '.bunsui' / 'logs')
            }
        }


def _collect_config_files(scope: str, include_secrets: bool, include_samples: bool) -> List[tuple[Path, Path]]:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†"""
    collected_files = []
    
    if scope in ['project', 'all']:
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®šã‚’åé›†
        project_root = find_project_root()
        if project_root:
            _collect_from_directory(
                project_root / '.bunsui', 
                collected_files, 
                include_secrets, 
                include_samples,
                base_name='project'
            )
    
    if scope in ['local', 'all']:
        # ãƒ­ãƒ¼ã‚«ãƒ«è¨­å®šã‚’åé›†
        _collect_from_directory(
            Path.cwd() / '.bunsui', 
            collected_files, 
            include_secrets, 
            include_samples,
            base_name='local'
        )
    
    if scope in ['global', 'all']:
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã‚’åé›†
        _collect_from_directory(
            Path.home() / '.bunsui', 
            collected_files, 
            include_secrets, 
            include_samples,
            base_name='global'
        )
    
    return collected_files


def _collect_from_directory(source_dir: Path, collected_files: List[tuple[Path, Path]], 
                           include_secrets: bool, include_samples: bool, base_name: str):
    """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†"""
    if not source_dir.exists():
        return
    
    for file_path in source_dir.rglob('*'):
        if not file_path.is_file():
            continue
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã«ã‚ˆã‚‹åˆ¤å®š
        file_name = file_path.name.lower()
        relative_path = file_path.relative_to(source_dir)
        
        # æ©Ÿå¯†ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯
        if 'secret' in file_name and not include_secrets:
            continue
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯
        if not include_samples and ('sample' in str(relative_path).lower() or 
                                   'example' in str(relative_path).lower()):
            continue
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã¯é™¤å¤–
        if any(exclude in str(relative_path).lower() for exclude in ['cache', 'logs', '__pycache__', '.pyc']):
            continue
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã§ã®ç›¸å¯¾ãƒ‘ã‚¹
        backup_relative_path = Path(base_name) / relative_path
        collected_files.append((file_path, backup_relative_path)) 


@config.command()
@click.option('--force', is_flag=True, help='ç¢ºèªãªã—ã§å®Ÿè¡Œ')
@click.option('--dry-run', is_flag=True, help='å®Ÿéš›ã«ã¯å¤‰æ›´ã›ãšã«å†…å®¹ã‚’è¡¨ç¤º')
@click.pass_context
def migrate(ctx: click.Context, force: bool, dry_run: bool):
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æœ€æ–°ã®æ¨å¥¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«æ›´æ–°"""
    try:
        _migrate_config_versions(force, dry_run)
    except Exception as e:
        console.print(f"[red]è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç§»è¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}[/red]")
        raise click.Abort()


def _migrate_config_versions(force: bool = False, dry_run: bool = False):
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æœ€æ–°ã®æ¨å¥¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«æ›´æ–°"""
    from pathlib import Path
    from rich.table import Table
    from rich.console import Console
    
    console = Console()
    
    # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³
    SUPPORTED_VERSIONS = ["1.0.0"]
    RECOMMENDED_VERSION = "1.0.0"
    
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢ãƒ‘ã‚¹
    config_paths = [
        Path.cwd() / '.bunsui' / 'config.yaml',
        Path.home() / '.bunsui' / 'config' / 'config.yaml',
        Path('/etc/bunsui/config.yaml')
    ]
    
    table = Table(title="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç§»è¡Œ", box=box.ROUNDED)
    table.add_column("ãƒ•ã‚¡ã‚¤ãƒ«", style="white", min_width=30)
    table.add_column("ç¾åœ¨ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³", style="white", min_width=15)
    table.add_column("æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³", style="white", min_width=15)
    table.add_column("çŠ¶æ…‹", style="white", min_width=15)
    
    files_to_migrate = []
    
    for config_path in config_paths:
        if config_path.exists():
            try:
                import yaml
                with open(config_path, 'r', encoding='utf-8') as f:
                    config_data = yaml.safe_load(f)
                
                current_version = config_data.get('version', 'æœªè¨­å®š')
                
                # ç§»è¡ŒãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯
                needs_migration = (
                    current_version == 'æœªè¨­å®š' or 
                    current_version not in SUPPORTED_VERSIONS or
                    current_version != RECOMMENDED_VERSION
                )
                
                if needs_migration:
                    files_to_migrate.append((config_path, config_data, current_version))
                    status = "[yellow]ç§»è¡Œäºˆå®š[/yellow]" if not dry_run else "[blue]ç¢ºèªã®ã¿[/blue]"
                else:
                    status = "[green]âœ“ æœ€æ–°[/green]"
                
                table.add_row(
                    str(config_path),
                    current_version,
                    RECOMMENDED_VERSION if needs_migration else current_version,
                    status
                )
                
            except Exception as e:
                table.add_row(
                    str(config_path),
                    "ã‚¨ãƒ©ãƒ¼",
                    RECOMMENDED_VERSION,
                    f"[red]èª­ã¿è¾¼ã¿å¤±æ•—: {e}[/red]"
                )
    
    if not files_to_migrate:
        console.print("[green]âœ“ ã™ã¹ã¦ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒæœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã™[/green]")
        return
    
    console.print(table)
    
    if dry_run:
        console.print(f"\n[blue]ç¢ºèªã®ã¿: {len(files_to_migrate)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒç§»è¡Œå¯¾è±¡ã§ã™[/blue]")
        return
    
    # ç¢ºèª
    if not force:
        if not Confirm.ask(f"\n{len(files_to_migrate)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ¼ã‚¸ãƒ§ãƒ³ {RECOMMENDED_VERSION} ã«æ›´æ–°ã—ã¾ã™ã‹ï¼Ÿ"):
            console.print("[yellow]ç§»è¡ŒãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ[/yellow]")
            return
    
    # ç§»è¡Œå®Ÿè¡Œ
    migrated_count = 0
    for config_path, config_data, current_version in files_to_migrate:
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            backup_path = config_path.with_suffix('.yaml.backup')
            import shutil
            shutil.copy2(config_path, backup_path)
            
            # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ›´æ–°
            config_data['version'] = RECOMMENDED_VERSION
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config_data, f, default_flow_style=False, allow_unicode=True)
            
            migrated_count += 1
            console.print(f"[green]âœ“ {config_path} ã‚’æ›´æ–°ã—ã¾ã—ãŸ (ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_path})[/green]")
            
        except Exception as e:
            console.print(f"[red]âœ— {config_path} ã®æ›´æ–°ã«å¤±æ•—: {e}[/red]")
    
    console.print(f"\n[green]âœ“ {migrated_count}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»è¡Œã—ã¾ã—ãŸ[/green]")
    console.print(f"[dim]æ¨å¥¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {RECOMMENDED_VERSION}[/dim]") 