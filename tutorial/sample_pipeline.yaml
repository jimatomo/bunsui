name: "サンプルETLパイプライン"
description: "CSVファイルからデータを読み取り、変換してS3に保存するサンプルパイプライン"
version: "1.0.0"
timeout_seconds: 3600
max_concurrent_jobs: 3

tags:
  environment: "tutorial"
  pipeline_type: "etl"
  team: "data-engineering"

metadata:
  created_by: "tutorial"
  created_at: "2024-01-20"
  purpose: "ETL学習用サンプル"

jobs:
  - job_id: "extract-job"
    name: "データ抽出"
    description: "S3からCSVファイルを読み取る"
    operations:
      - operation_id: "extract-csv"
        name: "Extract CSV from S3"
        config:
          operation_type: "lambda"
          resource_arn: "arn:aws:lambda:ap-northeast-1:123456789012:function:extract-csv-function"
          timeout_seconds: 300
          parameters:
            input_bucket: "sample-input-bucket"
            input_key: "data/input.csv"
    dependencies: []
    
  - job_id: "transform-job"
    name: "データ変換"
    description: "データのクレンジングと変換を実行"
    operations:
      - operation_id: "transform-data"
        name: "Transform Data"
        config:
          operation_type: "lambda"
          resource_arn: "arn:aws:lambda:ap-northeast-1:123456789012:function:transform-data-function"
          timeout_seconds: 900
          parameters:
            transformation_rules:
              convert_to_uppercase: true
              remove_duplicates: true
              validate_schema: true
    dependencies: ["extract-job"]
    
  - job_id: "load-job"
    name: "データロード"
    description: "変換されたデータをS3に保存"
    operations:
      - operation_id: "load-to-s3"
        name: "Load to S3"
        config:
          operation_type: "lambda"
          resource_arn: "arn:aws:lambda:ap-northeast-1:123456789012:function:load-to-s3-function"
          timeout_seconds: 600
          parameters:
            output_bucket: "sample-output-bucket"
            output_key: "data/output.parquet"
            format: "parquet"
    dependencies: ["transform-job"] 